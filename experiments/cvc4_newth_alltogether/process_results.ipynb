{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "root = Path('.')\n",
    "root = root.absolute()\n",
    "test_cases_root = root / \"testcases\"\n",
    "results_root = root / \"fmcad_results_2023-05-06_10-28-32/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root:  /home/eytan/Work/TheSy/experiments/cvc4_newth_alltogether\n",
      "test_cases_root:  /home/eytan/Work/TheSy/experiments/cvc4_newth_alltogether/testcases\n",
      "results_root:  /home/eytan/Work/TheSy/experiments/cvc4_newth_alltogether/fmcad_results_2023-05-06_10-28-32\n",
      "cwd:  /home/eytan/Work/TheSy/experiments/cvc4_newth_alltogether\n"
     ]
    }
   ],
   "source": [
    "print(\"root: \", root)\n",
    "print(\"test_cases_root: \", test_cases_root)\n",
    "print(\"results_root: \", results_root)\n",
    "# cwd\n",
    "print(\"cwd: \", Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [y for x in test_cases_root.iterdir() for y in x.iterdir() if y.suffix == \".th\"]\n",
    "rel_cases = [x.relative_to(test_cases_root) for x in test_cases]\n",
    "configs = [x.name for x in results_root.iterdir()]\n",
    "jsons = {n: pd.read_csv(results_root /  n / \"stats.csv\") for n in configs}\n",
    "# Rename columns such that Unnamed: 0 is the test suite nameL\n",
    "jsons = {n: j.rename(columns={\"Unnamed: 0\": \"test_suite\"}) for n, j in jsons.items()}\n",
    "# Assert test suite column of first configurations contains at least one case of clam\n",
    "assert any(jsons[configs[0]][\"test_suite\"].str.contains(\"clam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import NaN\n",
    "\n",
    "\n",
    "colored_stats = {}\n",
    "# Calculate relative_path for each test case\n",
    "for n, j in jsons.items():\n",
    "    j[\"relative_path\"] = j.apply(lambda x: (Path(x[\"test_suite\"]) / x['file_name'].replace('stats.json', 'th')), axis=1)\n",
    "    j[\"total_enodes\"] = NaN\n",
    "    # Find all existing colored_stats.json files by iterating over j['relative_path']\n",
    "    def collect_total(row):\n",
    "        x = row['relative_path']\n",
    "        # Find all colored_stats.json files\n",
    "        cs_path = results_root / n / x.with_suffix(\".colored_stats.json\")\n",
    "        if cs_path.exists():\n",
    "            with cs_path.open() as f:\n",
    "                cs = json.load(f)\n",
    "                colored_stats[(n, x)] = cs\n",
    "            filtered = [x[1] for x in cs]\n",
    "            for stats in filtered:\n",
    "                stats['total_enodes'] = stats['black_size']\n",
    "                if 'colors_sizes' in stats:\n",
    "                    stats['total_enodes'] += sum(stats['colors_sizes'].values())\n",
    "                if 'split_sizes' in stats:\n",
    "                    stats['total_enodes'] += sum(stats['split_sizes'])\n",
    "            # take max of total_enodes from filtered and add it to j\n",
    "            return max([x['total_enodes'] for x in filtered])\n",
    "        else:\n",
    "            return Nan\n",
    "    j['total_enodes'] = j.apply(collect_total, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start adding missing files by first adding an error column\n",
    "for j in jsons.values():\n",
    "    j[\"error\"] = None\n",
    "\n",
    "# Now add the missing files. For each missing case find the corresponding error file\n",
    "for n, j in jsons.items():\n",
    "    # Find missing cases by relative path to rel_cases\n",
    "    in_df = j['relative_path'].unique()\n",
    "    missing_cases = [r for r in rel_cases if r not in in_df]\n",
    "    for fn in missing_cases:\n",
    "        errors = (results_root / n / fn.with_suffix('.err')).read_text()\n",
    "        j.loc[len(j)] = {\"relative_path\": fn, \"error\": errors}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_split_proof_split_3_split_clone_keep_splits_stats\n",
      "error\n",
      "Timeout Exception                                 25\n",
      "memory allocation of 4194304 bytes failed\\n        1\n",
      "memory allocation of 1137600 bytes failed\\n        1\n",
      "memory allocation of 8 bytes failed\\n              1\n",
      "memory allocation of 11003664 bytes failed\\n       1\n",
      "memory allocation of 240 bytes failed\\n            1\n",
      "memory allocation of 1845493760 bytes failed\\n     1\n",
      "Name: count, dtype: int64\n",
      "case_split_proof_split_3_split_colored_stats\n",
      "error\n",
      "Timeout Exception                                  21\n",
      "memory allocation of 60129542144 bytes failed\\n     1\n",
      "memory allocation of 30064771072 bytes failed\\n     1\n",
      "Name: count, dtype: int64\n",
      "case_split_proof_split_4_split_colored_stats\n",
      "error\n",
      "Timeout Exception                                  39\n",
      "memory allocation of 60129542144 bytes failed\\n     1\n",
      "memory allocation of 30064771072 bytes failed\\n     1\n",
      "Name: count, dtype: int64\n",
      "case_split_proof_split_4_split_clone_keep_splits_stats\n",
      "error\n",
      "Timeout Exception                                  28\n",
      "memory allocation of 32 bytes failed\\n              2\n",
      "memory allocation of 160 bytes failed\\n             1\n",
      "memory allocation of 1203344 bytes failed\\n         1\n",
      "memory allocation of 8 bytes failed\\n               1\n",
      "memory allocation of 11001984 bytes failed\\n        1\n",
      "memory allocation of 60129542144 bytes failed\\n     1\n",
      "memory allocation of 29884432 bytes failed\\n        1\n",
      "Name: count, dtype: int64\n",
      "case_split_proof_split_2_split_clone_keep_splits_stats\n",
      "error\n",
      "Timeout Exception                                 4\n",
      "memory allocation of 1203344 bytes failed\\n       1\n",
      "memory allocation of 10998816 bytes failed\\n      1\n",
      "memory allocation of 11001984 bytes failed\\n      1\n",
      "memory allocation of 240 bytes failed\\n           1\n",
      "memory allocation of 1845493760 bytes failed\\n    1\n",
      "Name: count, dtype: int64\n",
      "case_split_proof_split_1_split_clone_keep_splits_stats\n",
      "error\n",
      "memory allocation of 8 bytes failed\\n             1\n",
      "memory allocation of 671140 bytes failed\\n        1\n",
      "memory allocation of 11004480 bytes failed\\n      1\n",
      "memory allocation of 240 bytes failed\\n           1\n",
      "memory allocation of 1207959568 bytes failed\\n    1\n",
      "Timeout Exception                                 1\n",
      "Name: count, dtype: int64\n",
      "case_split_proof_split_1_split_colored_stats\n",
      "error\n",
      "Timeout Exception    6\n",
      "Name: count, dtype: int64\n",
      "case_split_proof_split_2_split_colored_stats\n",
      "error\n",
      "Timeout Exception                                  6\n",
      "memory allocation of 60129542144 bytes failed\\n    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for c in configs:\n",
    "    if not ('keep' in c or 'colored' in c):\n",
    "        continue\n",
    "    # Filter errors by x is not None and ('Timeout' in x or 'memory' in x)\n",
    "    temp = jsons[c]['error'].apply(lambda x: x is not None and ('Timeout' in x or 'memory' in x))\n",
    "    print(c)\n",
    "    print(jsons[c][temp]['error'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "Timeout Exception                                                                                                                                                                                                                                                                                                                      39\n",
      "14:58:25 \u001b[0m\u001b[31m[ERROR] \u001b[0mUnrecognized token `(` found at 2707:2708\\nExpected one of \"then\"\\nthread 'main' panicked at 'Please implement error handling', src/thesy/semantics.rs:123:17\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\\n                                                           18\n",
      "thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: \"Found a list in the head position: [String(\\\"x\\\"), String(\\\"Nat\\\")]\"', src/bin/expl_experiment.rs:125:28\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\\n                                                                     13\n",
      "14:58:25 \u001b[0m\u001b[31m[ERROR] \u001b[0mUnrecognized token `(` found at 4357:4358\\nExpected one of \"then\"\\nthread 'main' panicked at 'Please implement error handling', src/thesy/semantics.rs:123:17\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\\n                                                           10\n",
      "15:00:02 \u001b[0m\u001b[31m[ERROR] \u001b[0mUnrecognized token `(` found at 4357:4358\\nExpected one of \"then\"\\nthread 'main' panicked at 'Please implement error handling', src/thesy/semantics.rs:123:17\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\\n                                                            2\n",
      "15:09:23 \u001b[0m\u001b[31m[ERROR] \u001b[0mInvalid token at 3928\\nthread 'main' panicked at 'Please implement error handling', src/thesy/semantics.rs:123:17\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\\n                                                                                                        2\n",
      "15:10:02 \u001b[0m\u001b[31m[ERROR] \u001b[0mInvalid token at 3928\\nthread 'main' panicked at 'Please implement error handling', src/thesy/semantics.rs:123:17\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\\n                                                                                                        2\n",
      "14:48:30 \u001b[0m\u001b[31m[ERROR] \u001b[0mUnrecognized token `s` found at 431:432\\nExpected one of \")\"\\nthread 'main' panicked at 'Please implement error handling', src/thesy/semantics.rs:123:17\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\\n                                                                 1\n",
      "14:50:04 \u001b[0m\u001b[31m[ERROR] \u001b[0mUnrecognized token `s` found at 541:542\\nExpected one of \")\"\\nthread 'main' panicked at 'Please implement error handling', src/thesy/semantics.rs:123:17\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\\n                                                                 1\n",
      "15:01:27 \u001b[0m\u001b[31m[ERROR] \u001b[0mUnrecognized token `s` found at 426:427\\nExpected one of \")\"\\nthread 'main' panicked at 'Please implement error handling', src/thesy/semantics.rs:123:17\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\\n                                                                 1\n",
      "14:50:04 \u001b[0m\u001b[31m[ERROR] \u001b[0mUnrecognized token `s` found at 466:467\\nExpected one of \")\"\\nthread 'main' panicked at 'Please implement error handling', src/thesy/semantics.rs:123:17\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\\n                                                                 1\n",
      "memory allocation of 60129542144 bytes failed\\n                                                                                                                                                                                                                                                                                         1\n",
      "14:53:04 \u001b[0m\u001b[31m[ERROR] \u001b[0mUnrecognized token `=>` found at 1247:1249\\nExpected one of \"(\", \"=\", \"?\", r#\"#[^#]+#\"# or r#\"[a-zA-Z+\\\\-/_*&$%^@0-9]+\"#\\nthread 'main' panicked at 'Please implement error handling', src/thesy/semantics.rs:123:17\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\\n     1\n",
      "14:58:38 \u001b[0m\u001b[31m[ERROR] \u001b[0mInvalid token at 3928\\nthread 'main' panicked at 'Please implement error handling', src/thesy/semantics.rs:123:17\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\\n                                                                                                        1\n",
      "14:59:19 \u001b[0m\u001b[31m[ERROR] \u001b[0mInvalid token at 3928\\nthread 'main' panicked at 'Please implement error handling', src/thesy/semantics.rs:123:17\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\\n                                                                                                        1\n",
      "15:00:04 \u001b[0m\u001b[31m[ERROR] \u001b[0mInvalid token at 3928\\nthread 'main' panicked at 'Please implement error handling', src/thesy/semantics.rs:123:17\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\\n                                                                                                        1\n",
      "15:00:02 \u001b[0m\u001b[31m[ERROR] \u001b[0mInvalid token at 3928\\nthread 'main' panicked at 'Please implement error handling', src/thesy/semantics.rs:123:17\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\\n                                                                                                        1\n",
      "memory allocation of 30064771072 bytes failed\\n                                                                                                                                                                                                                                                                                         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(jsons['case_split_proof_split_4_split_colored_stats']['error'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['test_suite', 'Unnamed: 1', 'time', 'stop_reasons', 'success',\n",
      "       'lemma_count', 'proofs_later_filtered', 'case_split_root_count',\n",
      "       'case_split_had_vacuity', 'total_allocated', 'max_allocated',\n",
      "       'file_name', 'relative_path', 'total_enodes', 'error'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>time</th>\n",
       "      <th>lemma_count</th>\n",
       "      <th>proofs_later_filtered</th>\n",
       "      <th>case_split_root_count</th>\n",
       "      <th>total_allocated</th>\n",
       "      <th>max_allocated</th>\n",
       "      <th>total_enodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>107.00000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1.070000e+02</td>\n",
       "      <td>1.070000e+02</td>\n",
       "      <td>107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.17757</td>\n",
       "      <td>2.043883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.785569e+09</td>\n",
       "      <td>8.232889e+06</td>\n",
       "      <td>409.196262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23.86788</td>\n",
       "      <td>18.744478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.591609e+10</td>\n",
       "      <td>6.549279e+07</td>\n",
       "      <td>1228.321553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.133249e+06</td>\n",
       "      <td>4.280190e+05</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.50000</td>\n",
       "      <td>0.003539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.895558e+06</td>\n",
       "      <td>4.349290e+05</td>\n",
       "      <td>97.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24.00000</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.271916e+06</td>\n",
       "      <td>4.441940e+05</td>\n",
       "      <td>135.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.50000</td>\n",
       "      <td>0.013615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.673392e+07</td>\n",
       "      <td>5.585015e+05</td>\n",
       "      <td>183.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.00000</td>\n",
       "      <td>193.843561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.644304e+11</td>\n",
       "      <td>6.761496e+08</td>\n",
       "      <td>10770.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 1        time  lemma_count  proofs_later_filtered   \n",
       "count   107.00000  107.000000        107.0                  107.0  \\\n",
       "mean     30.17757    2.043883          0.0                    0.0   \n",
       "std      23.86788   18.744478          0.0                    0.0   \n",
       "min       0.00000    0.002075          0.0                    0.0   \n",
       "25%       8.50000    0.003539          0.0                    0.0   \n",
       "50%      24.00000    0.004543          0.0                    0.0   \n",
       "75%      50.50000    0.013615          0.0                    0.0   \n",
       "max      77.00000  193.843561          0.0                    0.0   \n",
       "\n",
       "       case_split_root_count  total_allocated  max_allocated  total_enodes  \n",
       "count                  107.0     1.070000e+02   1.070000e+02    107.000000  \n",
       "mean                     0.0     1.785569e+09   8.232889e+06    409.196262  \n",
       "std                      0.0     1.591609e+10   6.549279e+07   1228.321553  \n",
       "min                      0.0     5.133249e+06   4.280190e+05     41.000000  \n",
       "25%                      0.0     5.895558e+06   4.349290e+05     97.500000  \n",
       "50%                      0.0     6.271916e+06   4.441940e+05    135.000000  \n",
       "75%                      0.0     1.673392e+07   5.585015e+05    183.500000  \n",
       "max                      0.0     1.644304e+11   6.761496e+08  10770.000000  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = list(jsons.values())[0]\n",
    "print(j.columns)\n",
    "j.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write our all new csv files as updated_stats.csv\n",
    "for n, j in jsons.items():\n",
    "    j.to_csv(results_root / (n[23:] + \"updated_stats.csv\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
